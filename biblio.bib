@misc{abdellaif2024,
  title = {{{LMRPA}}: {{Large Language Model-Driven Efficient Robotic Process Automation}} for {{OCR}}},
  shorttitle = {{{LMRPA}}},
  author = {Abdellaif, Osama Hosam and Nader, Abdelrahman and Hamdi, Ali},
  year = {2024},
  month = dec,
  number = {arXiv:2412.18063},
  eprint = {2412.18063},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.18063},
  url = {http://arxiv.org/abs/2412.18063},
  urldate = {2025-03-17},
  abstract = {This paper introduces LMRPA, a novel Large Model-Driven Robotic Process Automation (RPA) model designed to greatly improve the efficiency and speed of Optical Character Recognition (OCR) tasks. Traditional RPA platforms often suffer from performance bottlenecks when handling high-volume repetitive processes like OCR, leading to a less efficient and more time-consuming process. LMRPA allows the integration of Large Language Models (LLMs) to improve the accuracy and readability of extracted text, overcoming the challenges posed by ambiguous characters and complex text structures.Extensive benchmarks were conducted comparing LMRPA to leading RPA platforms, including UiPath and Automation Anywhere, using OCR engines like Tesseract and DocTR. The results are that LMRPA achieves superior performance, cutting the processing times by up to 52{\textbackslash}\%. For instance, in Batch 2 of the Tesseract OCR task, LMRPA completed the process in 9.8 seconds, where UiPath finished in 18.1 seconds and Automation Anywhere finished in 18.7 seconds. Similar improvements were observed with DocTR, where LMRPA outperformed other automation tools conducting the same process by completing tasks in 12.7 seconds, while competitors took over 20 seconds to do the same. These findings highlight the potential of LMRPA to revolutionize OCR-driven automation processes, offering a more efficient and effective alternative solution to the existing state-of-the-art RPA models.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Digital Libraries,Computer Science - Human-Computer Interaction,Computer Science - Robotics,Computer Science - Software Engineering},
  file = {/home/vini84200/Zotero/storage/VW7YT2SB/Abdellaif et al. - 2024 - LMRPA Large Language Model-Driven Efficient Robotic Process Automation for OCR.pdf;/home/vini84200/Zotero/storage/S8AZ7X3T/2412.html}
}

@inproceedings{araujo2024,
  title = {A Proposal for Post-{{OCR}} Spelling Correction Using {{Language Models}}},
  booktitle = {Latinx in {{AI}} @ {{NeurIPS}} 2024},
  author = {de Ara{\'u}jo, S{\'a}vio Santos and Bezerra, Byron Leite Dantas and Neto, Arthur Flor de Sousa and Zanchettin, Cleber},
  year = {2024},
  month = oct,
  url = {https://openreview.net/forum?id=p5P9R9AKr5},
  urldate = {2025-05-23},
  abstract = {This work explores the use of Language Models (LMs) to correct residual errors in texts extracted by OCR and HTR (Handwritten Text Recognition) systems. We propose a general approach but utilize the images from Brazilian handwritten essays of the BRESSAY dataset as a use case. Two standard LMs (Bart and ByT5) and two LLMs (LLama 1 and LLama 2) were evaluated in this context. The results indicate that the smaller LMs outperformed the LLMs in terms of error rate reduction (CER and WER). Traditional correction methods, such as Symspell and Norvig, were influential in some cases but fell short of the results obtained by the LMs. ByT5 with byte-level tokenization improved CER and WER, proving performance for texts with high noise. As a result, smaller LMs, after fine-tuning, are more efficient and cheaper for post-OCR corrections. We identify and propose promising future studies involving correction at broader levels of context, such as paragraphs. Code is available at https://github.com/savi8sant8s/ptbr-post-ocr-sc-llm.},
  langid = {english},
  file = {/home/vini84200/Zotero/storage/ZFCS4LIW/Ara√∫jo et al. - 2024 - A proposal for post-OCR spelling correction using Language Models.pdf}
}

@inproceedings{bazzo2020,
  title = {Assessing the {{Impact}} of {{OCR Errors}} in {{Information Retrieval}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Bazzo, Guilherme Torresan and Lorentz, Gustavo Acauan and Suarez Vargas, Danny and Moreira, Viviane P.},
  editor = {Jose, Joemon M. and Yilmaz, Emine and Magalh{\~a}es, Jo{\~a}o and Castells, Pablo and Ferro, Nicola and Silva, M{\'a}rio J. and Martins, Fl{\'a}vio},
  year = {2020},
  pages = {102--109},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-45442-5_13},
  abstract = {A significant amount of the textual content available on the Web is stored in PDF files. These files are typically converted into plain text before they can be processed by information retrieval or text mining systems. Automatic conversion typically introduces various errors, especially if OCR is needed. In this empirical study, we simulate OCR errors and investigate the impact that misspelled words have on retrieval accuracy. In order to quantify such impact, errors were systematically inserted at varying rates in an initially clean IR collection. Our results showed that significant impacts are noticed starting at a 5\% error rate. Furthermore, stemming has proven to make systems more robust to errors.},
  isbn = {978-3-030-45442-5},
  langid = {english},
  keywords = {application,Noisy text,OCR,relevanciaMed,Retrieval effectiveness},
  file = {/home/vini84200/Zotero/storage/62SGUPQZ/Bazzo et al. - 2020 - Assessing the Impact of OCR Errors in Information Retrieval.pdf}
}

@article{beshirov2025,
  title = {Post-Ocr Text Correction for {{Bulgarian}} Historical Documents},
  author = {Beshirov, Angel and Dobreva, Milena and Dimitrov, Dimitar and Hardalov, Momchil and Koychev, Ivan and Nakov, Preslav},
  year = {2025},
  month = feb,
  journal = {International Journal on Digital Libraries},
  volume = {26},
  number = {1},
  pages = {4},
  issn = {1432-1300},
  doi = {10.1007/s00799-025-00415-x},
  url = {https://doi.org/10.1007/s00799-025-00415-x},
  urldate = {2025-05-23},
  abstract = {The digitization of historical documents is crucial for preserving the cultural heritage of the society. An essential step in this process is converting scanned images to text using Optical Character Recognition (OCR), which can enable further search, information extraction, etc. Unfortunately, this is a challenging problem as standard OCR tools are not tailored to deal with historical orthography or challenging layouts. Thus, it is standard to apply an additional text correction step on the OCR output when dealing with such documents. In this work, we focus on Bulgarian, and we create the first benchmark dataset for evaluating the OCR text correction for historical Bulgarian documents written in the first standardized Bulgarian orthography: the Drinov orthography from the 19th century. We further develop a method for automatically generating synthetic data in this orthography, as well as in the subsequent Ivanchev orthography, by leveraging vast amounts of contemporary literature Bulgarian texts. We then use state-of-the-art LLMs and encoder-decoder framework which we augment with diagonal attention loss and copy and coverage mechanisms to improve the post-OCR text correction. The proposed method reduces the errors introduced during the recognition. It improves the quality of the documents by 25\%, which is an increase of 16\% compared to the state-of-the-art on the ICDAR 2019 Bulgarian dataset. We release our data and code at https://github.com/angelbeshirov/post-ocr-text-correction.},
  langid = {english},
  keywords = {/unread,Character-level sequence-to-sequence model,Digital Humanities,ESCRT,Historic-Post Medieval Archaeology,LLMs,Machine Translation,Orthographic variety,Orthography,Post-OCR text correction,Post-translational Modifications,Synthetic data},
  file = {/home/vini84200/Zotero/storage/P4CDH8S7/Beshirov et al. - 2025 - Post-ocr text correction for Bulgarian historical documents.pdf}
}

@article{boros,
  title = {Post-Correction of {{Historical Text Transcripts}} with {{Large Language Models}}: {{An Exploratory Study}}},
  author = {Boros, Emanuela and Ehrmann, Maud and Romanello, Matteo and {Najem-Meyer}, Sven and Kaplan, Fr{\'e}d{\'e}ric},
  abstract = {The quality of automatic transcription of heritage documents, whether from printed, manuscripts or audio sources, has a decisive impact on the ability to search and process historical texts. Although significant progress has been made in text recognition (OCR, HTR, ASR), textual materials derived from library and archive collections remain largely erroneous and noisy. Effective post-transcription correction methods are therefore necessary and have been intensively researched for many years. As large language models (LLMs) have recently shown exceptional performances in a variety of text-related tasks, we investigate their ability to amend poor historical transcriptions. We evaluate fourteen foundation language models against various post-correction benchmarks comprising different languages, time periods and document types, as well as different transcription quality and origins. We compare the performance of different model sizes and different prompts of increasing complexity in zero and few-shot settings. Our evaluation shows that LLMs are anything but efficient at this task. Quantitative and qualitative analyses of results allow us to share valuable insights for future work on post-correcting historical texts with LLMs.},
  langid = {english},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/ZIRHGQWL/Boros et al. - Post-correction of Historical Text Transcripts with Large Language Models An Exploratory Study.pdf}
}

@article{boros2022,
  title = {Assessing the Impact of {{OCR}} Noise on Multilingual Event Detection over Digitised Documents},
  author = {Boros, Emanuela and Nguyen, Nhu Khoa and Lejeune, Ga{\"e}l and Doucet, Antoine},
  year = {2022},
  month = sep,
  journal = {International Journal on Digital Libraries},
  volume = {23},
  number = {3},
  pages = {241--266},
  issn = {1432-1300},
  doi = {10.1007/s00799-022-00325-2},
  url = {https://doi.org/10.1007/s00799-022-00325-2},
  urldate = {2025-03-24},
  abstract = {Event detection is a crucial task for natural language processing and it involves the identification of instances of specified types of events in text and their classification into event types. The detection of events from digitised documents could enable historians to gather and combine a large amount of information into an integrated whole, a panoramic interpretation of the past. However, the level of degradation of digitised documents and the quality of the optical character recognition (OCR) tools might hinder the performance of an event detection system. While several studies have been performed in detecting events from historical documents, the transcribed documents needed to be hand-validated which implied a great effort of human expertise and manual labour-intensive work. Thus, in this study, we explore the robustness of two different event detection language-independent models to OCR noise, over two datasets that cover different event types and multiple languages. We aim at analysing their ability to mitigate problems caused by the low quality of the digitised documents and we simulate the existence of transcribed data, synthesised from clean annotated text, by injecting synthetic noise. For creating the noisy synthetic data, we chose to utilise four main types of noise that commonly occur after the digitisation process: Character Degradation, Bleed Through, Blur, and Phantom Character. Finally, we conclude that the imbalance of the datasets, the richness of the different annotation styles, and the language characteristics are the most important factors that can influence event detection in digitised documents.},
  langid = {english},
  keywords = {Digitised documents,Event detection,Information extraction},
  file = {/home/vini84200/Zotero/storage/Q7MSAPD4/Boros et al. - 2022 - Assessing the impact of OCR noise on multilingual event detection over digitised documents.pdf}
}

@misc{bourne2025,
  title = {{{CLOCR-C}}: {{Context Leveraging OCR Correction}} with {{Pre-trained Language Models}}},
  shorttitle = {{{CLOCR-C}}},
  author = {Bourne, Jonathan},
  year = {2025},
  month = jan,
  number = {arXiv:2408.17428},
  eprint = {2408.17428},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.17428},
  url = {http://arxiv.org/abs/2408.17428},
  urldate = {2025-03-17},
  abstract = {The digitisation of historical print media archives is crucial for increasing accessibility to contemporary records. However, the process of Optical Character Recognition (OCR) used to convert physical records to digital text is prone to errors, particularly in the case of newspapers and periodicals due to their complex layouts. This paper introduces Context Leveraging OCR Correction (CLOCR-C), which utilises the infilling and context-adaptive abilities of transformer-based language models (LMs) to improve OCR quality. The study aims to determine if LMs can perform post-OCR correction, improve downstream NLP tasks, and the value of providing the socio-cultural context as part of the correction process. Experiments were conducted using seven LMs on three datasets: the 19th Century Serials Edition (NCSE) and two datasets from the Overproof collection. The results demonstrate that some LMs can significantly reduce error rates, with the top-performing model achieving over a 60{\textbackslash}\% reduction in character error rate on the NCSE dataset. The OCR improvements extend to downstream tasks, such as Named Entity Recognition, with increased Cosine Named Entity Similarity. Furthermore, the study shows that providing socio-cultural context in the prompts improves performance, while misleading prompts lower performance. In addition to the findings, this study releases a dataset of 91 transcribed articles from the NCSE, containing a total of 40 thousand words, to support further research in this area. The findings suggest that CLOCR-C is a promising approach for enhancing the quality of existing digital archives by leveraging the socio-cultural information embedded in the LMs and the text requiring correction.},
  archiveprefix = {arXiv},
  keywords = {application,Computer Science - Computation and Language,Computer Science - Digital Libraries,english,llm,relevanciaMed,zeroshot},
  file = {/home/vini84200/Zotero/storage/BFP448DS/Bourne - 2025 - CLOCR-C Context Leveraging OCR Correction with Pre-trained Language Models.pdf;/home/vini84200/Zotero/storage/F4ZM8AAT/2408.html}
}

@article{bourne2025a,
  title = {Scrambled Text: Fine-Tuning Language Models for {{OCR}} Error Correction Using Synthetic Data},
  shorttitle = {Scrambled Text},
  author = {Bourne, Jonathan},
  year = {2025},
  month = apr,
  journal = {International Journal on Document Analysis and Recognition (IJDAR)},
  issn = {1433-2825},
  doi = {10.1007/s10032-025-00522-0},
  url = {https://doi.org/10.1007/s10032-025-00522-0},
  urldate = {2025-05-23},
  abstract = {OCR errors are common in digitised historical archives significantly affecting their usability and value. Generative Language Models (LMs) have shown potential for correcting these errors using the context provided by the corrupted text and the broader socio-cultural context, a process called Context Leveraging OCR Correction (CLOCR-C). However, getting sufficient training data for fine-tuning such models can prove challenging. This paper shows that fine-tuning a language model on synthetic data using an LM and using a character level Markov corruption process can significantly improve the ability to correct OCR errors. Models trained on synthetic data reduce the character error rate by 55\% and word error rate by 32\% over the base LM and outperform models trained on real data. Key findings include training on under-corrupted data is better than over-corrupted data; non-uniform character level corruption is better than uniform corruption; more tokens-per-observation outperforms more observations for a fixed token budget. The outputs for this paper are a set of 8 heuristics for training effective CLOCR-C models, a dataset of 11,000 synthetic 19th century newspaper articles and scrambledtext a python library for creating synthetic corrupted data.},
  langid = {english},
  keywords = {Computational Linguistics,Digital archives,ESCRT,Language Processing,Machine Translation,Natural Language Processing (NLP),NLP,OCR,Post-OCR correction,relevanciaMin,Technical Languages},
  file = {/home/vini84200/Zotero/storage/MRVJWZJF/Bourne - 2025 - Scrambled text fine-tuning language models for OCR error correction using synthetic data.pdf}
}

@inproceedings{chiron2017,
  title = {{{ICDAR2017 Competition}} on {{Post-OCR Text Correction}}},
  booktitle = {2017 14th {{IAPR International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  author = {Chiron, Guillaume and Doucet, Antoine and Coustaty, Micka{\"e}l and Moreux, Jean-Philippe},
  year = {2017},
  month = nov,
  volume = {01},
  pages = {1423--1428},
  issn = {2379-2140},
  doi = {10.1109/ICDAR.2017.232},
  url = {https://ieeexplore.ieee.org/document/8270163},
  urldate = {2025-05-26},
  abstract = {This paper describes the ICDAR2017 competition on post-OCR text correction and presents the different methods submitted by the participants. OCR has been an active research field for over the past 30 years but results are still imperfect, especially for historical documents. The purpose of this competition is to compare and evaluate automatic approaches for correcting (denoising) OCR-ed texts. The challenge consists of two independent tasks: 1) error detection and 2) error correction. An original dataset of 12M OCR-ed symbols along with an aligned ground truth was provided to the participants with 80\% of the dataset dedicated to the training and 20\% to the evaluation. Different sources were aggregated and namely contain newspapers and monographs covering 2 languages (English and French). 11 teams submitted results, while the difficulty of the task was underlined by the fact that only half of the submitted methods were able to denoise the evaluation dataset on average. In any case, this competition, which counted 35 registrations, illustrates the strong interest of the community in this essential problem, which is key to any digitization process involving textual data.},
  keywords = {/unread,Competition,Error correction,Libraries,Measurement,Optical character recognition software,Post-OCR,Task analysis,Text analysis,Text Correction,Training},
  file = {/home/vini84200/Zotero/storage/6XTG3TBA/Chiron et al. - 2017 - ICDAR2017 Competition on Post-OCR Text Correction.pdf}
}

@inproceedings{chiron2017a,
  title = {Impact of {{OCR Errors}} on the {{Use}} of {{Digital Libraries}}: {{Towards}} a {{Better Access}} to {{Information}}},
  shorttitle = {Impact of {{OCR Errors}} on the {{Use}} of {{Digital Libraries}}},
  booktitle = {2017 {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Chiron, Guillaume and Doucet, Antoine and Coustaty, Mickael and Visani, Muriel and Moreux, Jean-Philippe},
  year = {2017},
  month = jun,
  pages = {1--4},
  doi = {10.1109/JCDL.2017.7991582},
  url = {https://ieeexplore.ieee.org/abstract/document/7991582},
  urldate = {2025-05-26},
  abstract = {Digital collections are increasingly used for a variety of purposes. In Europe only, we can conservatively estimate that tens of thousands of users consult digital libraries daily. The usages are often motivated by qualitative and quantitative research. However, caution must be advised as most digitized documents are indexed through their OCRed version, which is far from perfect, especially for ancient documents. In this paper, we aim to estimate the impact of OCR errors on the use of a major online platform: The Gallica digital library from the National Library of France. It accounts for more than 100M OCRed documents and receives 80M search queries every year. In this context, we introduce two main contributions. First, an original corpus of OCRed documents composed of 12M characters along with the corresponding gold standard is presented and provided, with an equal share of English- and French-written documents. Next, statistics on OCR errors have been computed thanks to a novel alignment method introduced in this paper. Making use of all the user queries submitted to the Gallica portal over 4 months, we take advantage of our error model to propose an indicator for predicting the relative risk that queried terms mismatch targeted resources due to OCR errors, underlining the critical extent to which OCR quality impacts on digital library access.},
  keywords = {/unread,Engines,Europe,Gold,Layout,Libraries,Optical character recognition software,Standards},
  file = {/home/vini84200/Zotero/storage/ER82TP2D/Chiron et al. - 2017 - Impact of OCR Errors on the Use of Digital Libraries Towards a Better Access to Information.pdf}
}

@misc{davydkin2023,
  title = {Data {{Generation}} for {{Post-OCR}} Correction of {{Cyrillic}} Handwriting},
  author = {Davydkin, Evgenii and Markelov, Aleksandr and Iuldashev, Egor and Dudkin, Anton and Krivorotov, Ivan},
  year = {2023},
  month = nov,
  number = {arXiv:2311.15896},
  eprint = {2311.15896},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.15896},
  url = {http://arxiv.org/abs/2311.15896},
  urldate = {2025-03-23},
  abstract = {This paper introduces a novel approach to post-Optical Character Recognition Correction (POC) for handwritten Cyrillic text, addressing a significant gap in current research methodologies. This gap is due to the lack of large text corporas that provide OCR errors for further training of language-based POC models, which are demanding in terms of corpora size. Our study primarily focuses on the development and application of a synthetic handwriting generation engine based on B{\textbackslash}'ezier curves. Such an engine generates highly realistic handwritten text in any amounts, which we utilize to create a substantial dataset by transforming Russian text corpora sourced from the internet. We apply a Handwritten Text Recognition (HTR) model to this dataset to identify OCR errors, forming the basis for our POC model training. The correction model is trained on a 90-symbol input context, utilizing a pre-trained T5 architecture with a seq2seq correction task. We evaluate our approach on HWR200 and School\_notebooks\_RU datasets as they provide significant challenges in the HTR domain. Furthermore, POC can be used to highlight errors for teachers, evaluating student performance. This can be done simply by comparing sentences before and after correction, displaying differences in text. Our primary contribution lies in the innovative use of B{\textbackslash}'ezier curves for Cyrillic text generation and subsequent error correction using a specialized POC model. We validate our approach by presenting Word Accuracy Rate (WAR) and Character Accuracy Rate (CAR) results, both with and without post-OCR correction, using real open corporas of handwritten Cyrillic text. These results, coupled with our methodology, are designed to be reproducible, paving the way for further advancements in the field of OCR and handwritten text analysis. Paper contributions can be found in https://github.com/dbrainio/CyrillicHandwritingPOC},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/vini84200/Zotero/storage/ENVIK6N7/Davydkin et al. - 2023 - Data Generation for Post-OCR correction of Cyrillic handwriting.pdf;/home/vini84200/Zotero/storage/9NITYGQC/2311.html}
}

@inproceedings{dhondt2017,
  title = {Generating a {{Training Corpus}} for {{OCR Post-Correction Using Encoder-Decoder Model}}},
  booktitle = {Proceedings of the {{Eighth International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {D'hondt, Eva and Grouin, Cyril and Grau, Brigitte},
  editor = {Kondrak, Greg and Watanabe, Taro},
  year = {2017},
  month = nov,
  pages = {1006--1014},
  publisher = {Asian Federation of Natural Language Processing},
  address = {Taipei, Taiwan},
  url = {https://aclanthology.org/I17-1101/},
  urldate = {2025-03-23},
  abstract = {In this paper we present a novel approach to the automatic correction of OCR-induced orthographic errors in a given text. While current systems depend heavily on large training corpora or external information, such as domain-specific lexicons or confidence scores from the OCR process, our system only requires a small amount of (relatively) clean training data from a representative corpus to learn a character-based statistical language model using Bidirectional Long Short-Term Memory Networks (biLSTMs). We demonstrate the versatility and adaptability of our system on different text corpora with varying degrees of textual noise, including a real-life OCR corpus in the medical domain.},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/H8FS23BE/D'hondt et al. - 2017 - Generating a Training Corpus for OCR Post-Correction Using Encoder-Decoder Model.pdf}
}

@inproceedings{evershed2014,
  title = {Correcting Noisy {{OCR}}: Context Beats Confusion},
  shorttitle = {Correcting Noisy {{OCR}}},
  booktitle = {Proceedings of the {{First International Conference}} on {{Digital Access}} to {{Textual Cultural Heritage}}},
  author = {Evershed, John and Fitch, Kent},
  year = {2014},
  month = may,
  pages = {45--51},
  publisher = {ACM},
  address = {Madrid Spain},
  doi = {10.1145/2595188.2595200},
  url = {https://dl.acm.org/doi/10.1145/2595188.2595200},
  urldate = {2025-05-26},
  abstract = {We describe a system for automatic post OCR text correction of digital collections of historical texts. Documents, such as old newspapers, are often degraded, so even the best OCR tools can yield garbled text. When keywords are corrupted, text is invisible to search tools. Manual correction is not feasible for large collections. Our non-interactive OCR correction method uses a "noisy channel" approach. The error model uses statistically weighted multiple character edits and a novel visual correlation adjustment using low resolution "reverse OCR". The language model uses normal and also "gap" word 3-grams, plus some 5grams. Word correction candidates are generated by a deep heuristic search of weighted edit combinations guided by a trie. Testing shows good improvements in word error rate. Experiments demonstrate resilience and justify the use of a deep candidate search.},
  isbn = {978-1-4503-2588-2},
  langid = {english},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/RL5Z8WUZ/Evershed e Fitch - 2014 - Correcting noisy OCR context beats confusion.pdf}
}

@inproceedings{grundkiewicz2019,
  title = {Neural {{Grammatical Error Correction Systems}} with {{Unsupervised Pre-training}} on {{Synthetic Data}}},
  booktitle = {Proceedings of the {{Fourteenth Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}}},
  author = {Grundkiewicz, Roman and {Junczys-Dowmuntz}, Marcin and Heafield, Kenneth},
  year = {2019},
  month = aug,
  publisher = {Association for Computational Linguistics},
  url = {https://www.research.ed.ac.uk/en/publications/neural-grammatical-error-correction-systems-with-unsupervised-pre},
  urldate = {2025-03-23},
  langid = {english},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/XZKXDRSB/Grundkiewicz et al. - 2019 - Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data.pdf}
}

@misc{guan2024,
  title = {Advancing {{Post-OCR Correction}}: {{A Comparative Study}} of {{Synthetic Data}}},
  shorttitle = {Advancing {{Post-OCR Correction}}},
  author = {Guan, Shuhao and Greene, Derek},
  year = {2024},
  month = aug,
  number = {arXiv:2408.02253},
  eprint = {2408.02253},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.02253},
  url = {http://arxiv.org/abs/2408.02253},
  urldate = {2025-03-17},
  abstract = {This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages computer vision feature detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several low-resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually annotated data, and our proposed synthetic data generation method shows advantages over traditional methods, particularly in low-resource languages.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Sythetic OCR},
  file = {/home/vini84200/Zotero/storage/TJW5VVRN/Guan e Greene - 2024 - Advancing Post-OCR Correction A Comparative Study of Synthetic Data.pdf;/home/vini84200/Zotero/storage/CYUJJDDC/2408.html}
}

@misc{hsu2025,
  title = {{{KAP}}: {{MLLM-assisted OCR Text Enhancement}} for {{Hybrid Retrieval}} in {{Chinese Non-Narrative Documents}}},
  shorttitle = {{{KAP}}},
  author = {Hsu, Hsin-Ling and Lin, Ping-Sheng and Lin, Jing-Di and Tzeng, Jengnan},
  year = {2025},
  month = mar,
  number = {arXiv:2503.08452},
  eprint = {2503.08452},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.08452},
  url = {http://arxiv.org/abs/2503.08452},
  urldate = {2025-03-17},
  abstract = {We propose Knowledge-Aware Preprocessing (KAP), a two-stage preprocessing framework tailored for Traditional Chinese non-narrative documents, designed to enhance retrieval accuracy in Hybrid Retrieval systems. Hybrid Retrieval, which integrates Sparse Retrieval (e.g., BM25) and Dense Retrieval (e.g., vector embeddings), has become a widely adopted approach for improving search effectiveness. However, its performance heavily depends on the quality of input text, which is often degraded when dealing with non-narrative documents such as PDFs containing financial statements, contractual clauses, and tables. KAP addresses these challenges by integrating Multimodal Large Language Models (MLLMs) with LLM-driven post-OCR processing, refining extracted text to reduce OCR noise, restore table structures, and optimize text format. By ensuring better compatibility with Hybrid Retrieval, KAP improves the accuracy of both Sparse and Dense Retrieval methods without modifying the retrieval architecture itself.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Information Retrieval},
  file = {/home/vini84200/Zotero/storage/IDDLBH85/Hsu et al. - 2025 - KAP MLLM-assisted OCR Text Enhancement for Hybrid Retrieval in Chinese Non-Narrative Documents.pdf;/home/vini84200/Zotero/storage/BCCXGPXY/2503.html}
}

@misc{ignat2022,
  title = {{{OCR Improves Machine Translation}} for {{Low-Resource Languages}}},
  author = {Ignat, Oana and Maillard, Jean and Chaudhary, Vishrav and Guzm{\'a}n, Francisco},
  year = {2022},
  month = mar,
  number = {arXiv:2202.13274},
  eprint = {2202.13274},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.13274},
  url = {http://arxiv.org/abs/2202.13274},
  urldate = {2025-03-23},
  abstract = {We aim to investigate the performance of current OCR systems on low resource languages and low resource scripts. We introduce and make publicly available a novel benchmark, OCR4MT, consisting of real and synthetic data, enriched with noise, for 60 low-resource languages in low resource scripts. We evaluate state-of-the-art OCR systems on our benchmark and analyse most common errors. We show that OCR monolingual data is a valuable resource that can increase performance of Machine Translation models, when used in backtranslation. We then perform an ablation study to investigate how OCR errors impact Machine Translation performance and determine what is the minimum level of OCR quality needed for the monolingual data to be useful for Machine Translation.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computation and Language},
  file = {/home/vini84200/Zotero/storage/46IHQ3NG/Ignat et al. - 2022 - OCR Improves Machine Translation for Low-Resource Languages.pdf;/home/vini84200/Zotero/storage/5UYBP3LI/2202.html}
}

@misc{jaderberg2014,
  title = {Synthetic {{Data}} and {{Artificial Neural Networks}} for {{Natural Scene Text Recognition}}},
  author = {Jaderberg, Max and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  year = {2014},
  month = dec,
  number = {arXiv:1406.2227},
  eprint = {1406.2227},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1406.2227},
  url = {http://arxiv.org/abs/1406.2227},
  urldate = {2025-03-24},
  abstract = {In this work we present a framework for the recognition of natural scene text. Our framework does not require any human-labelled data, and performs word recognition on the whole image holistically, departing from the character based recognition systems of the past. The deep neural network models at the centre of this framework are trained solely on data produced by a synthetic text generation engine -- synthetic data that is highly realistic and sufficient to replace real data, giving us infinite amounts of training data. This excess of data exposes new possibilities for word recognition models, and here we consider three models, each one "reading" words in a different way: via 90k-way dictionary encoding, character sequence encoding, and bag-of-N-grams encoding. In the scenarios of language based and completely unconstrained text recognition we greatly improve upon state-of-the-art performance on standard datasets, using our fast, simple machinery and requiring zero data-acquisition costs.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/vini84200/Zotero/storage/NKJGBHS5/Jaderberg et al. - 2014 - Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition.pdf;/home/vini84200/Zotero/storage/6NCLYJV9/1406.html}
}

@inproceedings{jasonarson2023,
  title = {Generating {{Errors}}: {{OCR Post-Processing}} for {{Icelandic}}},
  shorttitle = {Generating {{Errors}}},
  booktitle = {Proceedings of the 24th {{Nordic Conference}} on {{Computational Linguistics}} ({{NoDaLiDa}})},
  author = {Jasonarson, Atli and Steingr{\'i}msson, Stein{\th}{\'o}r and Sigur{\dh}sson, Einar and Magn{\'u}sson, {\'A}rni and Ingimundarson, Finnur},
  editor = {Alum{\"a}e, Tanel and Fishel, Mark},
  year = {2023},
  month = may,
  pages = {286--291},
  publisher = {University of Tartu Library},
  address = {T{\'o}rshavn, Faroe Islands},
  url = {https://aclanthology.org/2023.nodalida-1.29/},
  urldate = {2025-03-23},
  abstract = {We describe work on enhancing the performance of transformer-based encoder-decoder models for OCR post-correction on modern and historical Icelandic texts, where OCRed data are scarce. We trained six models, four from scratch and two fine-tuned versions of Google`s ByT5, on a combination of real data and texts populated with artificially generated errors. Our results show that the models trained from scratch, as opposed to the fine-tuned versions, benefited the most from the addition of artificially generated errors.},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/8GZBUTGH/Jasonarson et al. - 2023 - Generating Errors OCR Post-Processing for Icelandic.pdf}
}

@inproceedings{jatowt2019,
  title = {Deep {{Statistical Analysis}} of {{OCR Errors}} for {{Effective Post-OCR Processing}}},
  booktitle = {2019 {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Jatowt, Adam and Nguyen, Thi-Tuyet-Hai and Coustaty, Mickael and Nguyen, Nhu-Van and Doucet, Antoine},
  year = {2019},
  month = jun,
  pages = {29--38},
  doi = {10.1109/JCDL.2019.00015},
  url = {https://ieeexplore.ieee.org/abstract/document/8791206},
  urldate = {2025-03-23},
  abstract = {Post-OCR is an important processing step that follows optical character recognition (OCR) and is meant to improve the quality of OCR documents by detecting and correcting residual errors. This paper describes the results of a statistical analysis of OCR errors on four document collections. Five aspects related to general OCR errors are studied and compared with human-generated misspellings, including edit operations, length effects, erroneous character positions, real-word vs. non-word errors, and word boundaries. Based on the observations from the analysis we give several suggestions related to the design and implementation of effective OCR post-processing approaches.},
  keywords = {/unread,Character recognition,Error analysis,Feature extraction,Libraries,OCR errors OCR post-processing post OCR text correction,Optical character recognition software,relevanciaMed,Statistical analysis,Transducers},
  file = {/home/vini84200/Zotero/storage/7EG6GGG3/Nguyen et al. - 2019 - Deep Statistical Analysis of OCR Errors for Effective Post-OCR Processing.pdf;/home/vini84200/Zotero/storage/TIPCP6Y2/8791206.html}
}

@misc{kanerva2025,
  title = {{{OCR Error Post-Correction}} with {{LLMs}} in {{Historical Documents}}: {{No Free Lunches}}},
  shorttitle = {{{OCR Error Post-Correction}} with {{LLMs}} in {{Historical Documents}}},
  author = {Kanerva, Jenna and Ledins, Cassandra and K{\"a}pyaho, Siiri and Ginter, Filip},
  year = {2025},
  month = feb,
  number = {arXiv:2502.01205},
  eprint = {2502.01205},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.01205},
  url = {http://arxiv.org/abs/2502.01205},
  urldate = {2025-03-17},
  abstract = {Optical Character Recognition (OCR) systems often introduce errors when transcribing historical documents, leaving room for post-correction to improve text quality. This study evaluates the use of open-weight LLMs for OCR error correction in historical English and Finnish datasets. We explore various strategies, including parameter optimization, quantization, segment length effects, and text continuation methods. Our results demonstrate that while modern LLMs show promise in reducing character error rates (CER) in English, a practically useful performance for Finnish was not reached. Our findings highlight the potential and limitations of LLMs in scaling OCR post-correction for large historical corpora.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,english,Post-OCR correction,relevanciaMed,zeroshot},
  file = {/home/vini84200/Zotero/storage/2BX2MBEB/Kanerva et al. - 2025 - OCR Error Post-Correction with LLMs in Historical Documents No Free Lunches.pdf;/home/vini84200/Zotero/storage/P67EJ5WL/2502.html}
}

@misc{krishna2018,
  title = {Upcycle {{Your OCR}}: {{Reusing OCRs}} for {{Post-OCR Text Correction}} in {{Romanised Sanskrit}}},
  shorttitle = {Upcycle {{Your OCR}}},
  author = {Krishna, Amrith and Majumder, Bodhisattwa Prasad and Bhat, Rajesh Shreedhar and Goyal, Pawan},
  year = {2018},
  month = sep,
  number = {arXiv:1809.02147},
  eprint = {1809.02147},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1809.02147},
  url = {http://arxiv.org/abs/1809.02147},
  urldate = {2025-03-24},
  abstract = {We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit. Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman. Currently, there exists no dataset available for Romanised Sanskrit OCR. So, we bootstrap a dataset of 430 images, scanned in two different settings and their corresponding ground truth. For training, we synthetically generate training images for both the settings. We find that the use of copying mechanism (Gu et al., 2016) yields a percentage increase of 7.69 in Character Recognition Rate (CRR) than the current state of the art model in solving monotone sequence-to-sequence tasks (Schnober et al., 2016). We find that our system is robust in combating OCR-prone errors, as it obtains a CRR of 87.01\% from an OCR output with CRR of 35.76\% for one of the dataset settings. A human judgment survey performed on the models shows that our proposed model results in predictions which are faster to comprehend and faster to improve for a human than the other systems.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computation and Language},
  file = {/home/vini84200/Zotero/storage/RBG486QI/Krishna et al. - 2018 - Upcycle Your OCR Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit.pdf;/home/vini84200/Zotero/storage/8Y8EZRKS/1809.html}
}

@inproceedings{lund2009,
  title = {Improving Optical Character Recognition through Efficient Multiple System Alignment},
  booktitle = {Proceedings of the 9th {{ACM}}/{{IEEE-CS}} Joint Conference on {{Digital}} Libraries},
  author = {Lund, William B. and Ringger, Eric K.},
  year = {2009},
  month = jun,
  pages = {231--240},
  publisher = {ACM},
  address = {Austin TX USA},
  doi = {10.1145/1555400.1555437},
  url = {https://dl.acm.org/doi/10.1145/1555400.1555437},
  urldate = {2025-05-31},
  abstract = {Individual optical character recognition (OCR) engines vary in the types of errors they commit in recognizing text, particularly poor quality text. By aligning the output of multiple OCR engines and taking advantage of the differences between them, the error rate based on the aligned lattice of recognized words is significantly lower than the individual OCR word error rates. This lattice error rate constitutes a lower bound among aligned alternatives from the OCR output. Results from a collection of poor quality midtwentieth century typewritten documents demonstrate an average reduction of 55.0\% in the error rate of the lattice of alternatives and a realized word error rate (WER) reduction of 35.8\% in a dictionary-based selection process. As an important precursor, an innovative admissible heuristic for the A* algorithm is developed, which results in a significant reduction in state space exploration to identify all optimal alignments of the OCR text output, a necessary step toward the construction of the word hypothesis lattice. On average 0.0079\% of the state space is explored to identify all optimal alignments of the documents.},
  isbn = {978-1-60558-322-8},
  langid = {english},
  keywords = {/unread,relevanciaMin},
  file = {/home/vini84200/Zotero/storage/ARBTPW92/Lund e Ringger - 2009 - Improving optical character recognition through efficient multiple system alignment.pdf}
}

@misc{nassar2025,
  title = {{{SmolDocling}}: {{An}} Ultra-Compact Vision-Language Model for End-to-End Multi-Modal Document Conversion},
  shorttitle = {{{SmolDocling}}},
  author = {Nassar, Ahmed and Marafioti, Andres and Omenetti, Matteo and Lysak, Maksym and Livathinos, Nikolaos and Auer, Christoph and Morin, Lucas and de Lima, Rafael Teixeira and Kim, Yusik and Gurbuz, A. Said and Dolfi, Michele and Farr{\'e}, Miquel and Staar, Peter W. J.},
  year = {2025},
  month = mar,
  number = {arXiv:2503.11576},
  eprint = {2503.11576},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.11576},
  url = {http://arxiv.org/abs/2503.11576},
  urldate = {2025-03-17},
  abstract = {We introduce SmolDocling, an ultra-compact vision-language model targeting end-to-end document conversion. Our model comprehensively processes entire pages by generating DocTags, a new universal markup format that captures all page elements in their full context with location. Unlike existing approaches that rely on large foundational models, or ensemble solutions that rely on handcrafted pipelines of multiple specialized models, SmolDocling offers an end-to-end conversion for accurately capturing content, structure and spatial location of document elements in a 256M parameters vision-language model. SmolDocling exhibits robust performance in correctly reproducing document features such as code listings, tables, equations, charts, lists, and more across a diverse range of document types including business documents, academic papers, technical reports, patents, and forms --- significantly extending beyond the commonly observed focus on scientific papers. Additionally, we contribute novel publicly sourced datasets for charts, tables, equations, and code recognition. Experimental results demonstrate that SmolDocling competes with other Vision Language Models that are up to 27 times larger in size, while reducing computational requirements substantially. The model is currently available, datasets will be publicly available soon.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/vini84200/Zotero/storage/8EP5EK4P/Nassar et al. - 2025 - SmolDocling An ultra-compact vision-language model for end-to-end multi-modal document conversion.pdf}
}

@inproceedings{neudecker2021,
  title = {A Survey of {{OCR}} Evaluation Tools and Metrics},
  booktitle = {The 6th {{International Workshop}} on {{Historical Document Imaging}} and {{Processing}}},
  author = {Neudecker, Clemens and Baierer, Konstantin and Gerber, Mike and Clausner, Christian and Antonacopoulos, Apostolos and Pletschacher, Stefan},
  year = {2021},
  month = sep,
  pages = {13--18},
  publisher = {ACM},
  address = {Lausanne Switzerland},
  doi = {10.1145/3476887.3476888},
  url = {https://dl.acm.org/doi/10.1145/3476887.3476888},
  urldate = {2025-05-26},
  abstract = {The millions of pages of historical documents that are digitized in libraries are increasingly used in contexts that have more specific requirements for OCR quality than keyword search. How to comprehensively, efficiently and reliably assess the quality of OCR results against the background of mass digitization, when ground truth can only ever be produced for very small numbers? Due to gaps in specifications, results from OCR evaluation tools can return different results, and due to differences in implementation, even commonly used error rates are often not directly comparable. OCR evaluation metrics and sampling methods are also not sufficient where they do not take into account the accuracy of layout analysis, since for advanced use cases like Natural Language Processing or the Digital Humanities, accurate layout analysis and detection of the reading order are crucial. We provide an overview of OCR evaluation metrics and tools, describe two advanced use cases for OCR results, and perform an OCR evaluation experiment with multiple evaluation tools and different metrics for two distinct datasets. We analyze the differences and commonalities in light of the presented use cases and suggest areas for future work.},
  isbn = {978-1-4503-8690-6},
  langid = {english},
  file = {/home/vini84200/Zotero/storage/7BX8KSIJ/Neudecker et al. - 2021 - A survey of OCR evaluation tools and metrics.pdf}
}

@inproceedings{nguyen2020,
  title = {Neural {{Machine Translation}} with {{BERT}} for {{Post-OCR Error Detection}} and {{Correction}}},
  booktitle = {{{JCDL}} '20: {{The ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} in 2020},
  author = {Nguyen, Thi Tuyet Hai and Jatowt, Adam and Nguyen, Nhu-Van and Coustaty, Micka{\"e}l and Doucet, Antoine},
  year = {2020},
  month = aug,
  pages = {333--336},
  publisher = {ACM},
  address = {Virtual Event, China},
  doi = {10.1145/3383583.3398605},
  url = {https://hal.science/hal-03026937},
  urldate = {2025-03-23},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/EAM6ZW9L/Nguyen et al. - 2020 - Neural Machine Translation with BERT for Post-OCR Error Detection and Correction.pdf}
}

@article{nguyen2022,
  title = {Survey of {{Post-OCR Processing Approaches}}},
  author = {Nguyen, Thi Tuyet Hai and Jatowt, Adam and Coustaty, Mickael and Doucet, Antoine},
  year = {2022},
  month = jul,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {6},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3453476},
  url = {https://dl.acm.org/doi/10.1145/3453476},
  urldate = {2025-05-26},
  abstract = {Optical character recognition (OCR) is one of the most popular techniques used for converting printed documents into machine-readable ones. While OCR engines can do well with modern text, their performance is unfortunately significantly reduced on historical materials. Additionally, many texts have already been processed by various out-of-date digitisation techniques. As a consequence, digitised texts are noisy and need to be post-corrected. This article clarifies the importance of enhancing quality of OCR results by studying their effects on information retrieval and natural language processing applications. We then define the post-OCR processing problem, illustrate its typical pipeline, and review the state-of-the-art post-OCR processing approaches. Evaluation metrics, accessible datasets, language resources, and useful toolkits are also reported. Furthermore, the work identifies the current trend and outlines some research directions of this field.},
  langid = {english},
  keywords = {relevanciaMax},
  file = {/home/vini84200/Zotero/storage/EVIZ57MA/Nguyen et al. - 2022 - Survey of Post-OCR Processing Approaches.pdf}
}

@inproceedings{rigaud2019,
  title = {{{ICDAR}} 2019 {{Competition}} on {{Post-OCR Text Correction}}},
  booktitle = {2019 {{International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  author = {Rigaud, Christophe and Doucet, Antoine and Coustaty, Micka{\"e}l and Moreux, Jean-Philippe},
  year = {2019},
  month = sep,
  pages = {1588--1593},
  issn = {2379-2140},
  doi = {10.1109/ICDAR.2019.00255},
  url = {https://ieeexplore.ieee.org/abstract/document/8978127},
  urldate = {2025-05-26},
  abstract = {This paper describes the second round of the ICDAR 2019 competition on post-OCR text correction and presents the different methods submitted by the participants. OCR has been an active research field for over the past 30 years but results are still imperfect, especially for historical documents. The purpose of this competition is to compare and evaluate automatic approaches for correcting (denoising) OCR-ed texts. The present challenge consists of two tasks: 1) error detection and 2) error correction. An original dataset of 22M OCR-ed symbols along with an aligned ground truth was provided to the participants with 80\% of the dataset dedicated to training and 20\% to evaluation. Different sources were aggregated and contain newspapers, historical printed documents as well as manuscripts and shopping receipts, covering 10 European languages (Bulgarian, Czech, Dutch, English, Finish, French, German, Polish, Spanish and Slovak). Five teams submitted results, the error detection scores vary from 41 to 95\% and the best error correction improvement is 44\%. This competition, which counted 34 registrations, illustrates the strong interest of the community to improve OCR output, which is a key issue to any digitization process involving textual data.},
  keywords = {/unread,Dictionaries,Error correction,Libraries,OCR,Optical character recognition software,Task analysis,text recognition,Tools,Training},
  file = {/home/vini84200/Zotero/storage/VDBQKDP9/Rigaud et al. - 2019 - ICDAR 2019 Competition on Post-OCR Text Correction.pdf}
}

@inproceedings{rijhwani2020,
  title = {{{OCR Post Correction}} for {{Endangered Language Texts}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Rijhwani, Shruti and Anastasopoulos, Antonios and Neubig, Graham},
  editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020},
  month = nov,
  pages = {5931--5942},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.emnlp-main.478},
  url = {https://aclanthology.org/2020.emnlp-main.478/},
  urldate = {2025-03-17},
  abstract = {There is little to no data available to build natural language processing models for most endangered languages. However, textual data in these languages often exists in formats that are not machine-readable, such as paper books and scanned images. In this work, we address the task of extracting text from these resources. We create a benchmark dataset of transcriptions for scanned books in three critically endangered languages and present a systematic analysis of how general-purpose OCR tools are not robust to the data-scarce setting of endangered languages. We develop an OCR post-correction method tailored to ease training in this data-scarce setting, reducing the recognition error rate by 34\% on average across the three languages.},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/BZIU33FG/Rijhwani et al. - 2020 - OCR Post Correction for Endangered Language Texts.pdf}
}

@inproceedings{santos2005,
  title = {The {{Key}} to the {{First CLEF}} with {{Portuguese}}: {{Topics}}, {{Questions}} and {{Answers}} in {{CHAVE}}},
  shorttitle = {The {{Key}} to the {{First CLEF}} with {{Portuguese}}},
  booktitle = {Multilingual {{Information Access}} for {{Text}}, {{Speech}} and {{Images}}},
  author = {Santos, Diana and Rocha, Paulo},
  editor = {Peters, Carol and Clough, Paul and Gonzalo, Julio and Jones, Gareth J. F. and Kluck, Michael and Magnini, Bernardo},
  year = {2005},
  pages = {821--832},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11519645_80},
  abstract = {In this paper we report the work done by Linguateca in order to add Portuguese to two tracks of CLEF, namely the ad hoc IR and the QA tracks. We start with a brief description of Linguateca's aims and the way we see CLEF from the standpoint of Portuguese language processing. We then comment on several interesting problems that emerged during our work and offer some suggestions for improvement, and finally raise some possibly controversial points for discussion.},
  isbn = {978-3-540-32051-7},
  langid = {english},
  keywords = {Feminine Form,Feminine Noun,Iranian Cinema,Portuguese Speaker,Topic Preparation},
  file = {/home/vini84200/Zotero/storage/99AJ5AVT/Santos e Rocha - 2005 - The Key to the First CLEF with Portuguese Topics, Questions and Answers in CHAVE.pdf}
}

@inproceedings{santos2023,
  title = {{{ESTER-Pt}}: {{An Evaluation Suite}} for~{{TExt Recognition}} in~{{Portuguese}}},
  shorttitle = {{{ESTER-Pt}}},
  booktitle = {Document {{Analysis}} and {{Recognition}} - {{ICDAR}} 2023},
  author = {Santos, Moniele Kunrath and Bazzo, Guilherme and {de Oliveira}, Lucas Lima and Moreira, Viviane Pereira},
  editor = {Fink, Gernot A. and Jain, Rajiv and Kise, Koichi and Zanibbi, Richard},
  year = {2023},
  pages = {366--383},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-41682-8_23},
  abstract = {Optical Character Recognition (OCR) is a technology that enables machines to read and interpret printed or handwritten texts from scanned images or photographs. However, the accuracy of OCR systems can vary depending on several factors, such as the quality of the input image, the font used, and the language of the document. As a general tendency, OCR algorithms perform better in resource-rich languages as they have more annotated data to train the recognition process. In this work, we propose ESTER-Pt, an Evaluation Suite for TExt Recognition in Portuguese. Despite being one of the largest languages in terms of speakers, OCR in Portuguese remains largely unexplored. Our evaluation suite comprises four types of resources: synthetic text-based documents, synthetic image-based documents, real scanned documents, and a hybrid set with real image-based documents that were synthetically degraded. Additionally, we provide results of OCR engines and post-OCR correction tools on ESTER-Pt, which can serve as a baseline for future work.},
  isbn = {978-3-031-41682-8},
  langid = {english},
  keywords = {relevanciaMax},
  file = {/home/vini84200/Zotero/storage/T4A6SGIG/Santos et al. - 2023 - ESTER-Pt An Evaluation Suite for¬†TExt Recognition in¬†Portuguese.pdf}
}

@inproceedings{soper2021,
  title = {{{BART}} for {{Post-Correction}} of {{OCR Newspaper Text}}},
  booktitle = {Proceedings of the {{Seventh Workshop}} on {{Noisy User-generated Text}} ({{W-NUT}} 2021)},
  author = {Soper, Elizabeth and Fujimoto, Stanley and Yu, Yen-Yun},
  editor = {Xu, Wei and Ritter, Alan and Baldwin, Tim and Rahimi, Afshin},
  year = {2021},
  month = nov,
  pages = {284--290},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2021.wnut-1.31},
  url = {https://aclanthology.org/2021.wnut-1.31/},
  urldate = {2025-03-23},
  abstract = {Optical character recognition (OCR) from newspaper page images is susceptible to noise due to degradation of old documents and variation in typesetting. In this report, we present a novel approach to OCR post-correction. We cast error correction as a translation task, and fine-tune BART, a transformer-based sequence-to-sequence language model pretrained to denoise corrupted text. We are the first to use sentence-level transformer models for OCR post-correction, and our best model achieves a 29.4\% improvement in character accuracy over the original noisy OCR text. Our results demonstrate the utility of pretrained language models for dealing with noisy text.},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/ZNJHKXBY/Soper et al. - 2021 - BART for Post-Correction of OCR Newspaper Text.pdf}
}

@inproceedings{sorensen2022,
  title = {An {{Information-theoretic Approach}} to {{Prompt Engineering Without Ground Truth Labels}}},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Sorensen, Taylor and Robinson, Joshua and Rytting, Christopher Michael and Shaw, Alexander Glenn and Rogers, Kyle Jeffrey and Delorey, Alexia Pauline and Khalil, Mahmoud and Fulda, Nancy and Wingate, David},
  year = {2022},
  eprint = {2203.11364},
  primaryclass = {cs},
  pages = {819--862},
  doi = {10.18653/v1/2022.acl-long.60},
  url = {http://arxiv.org/abs/2203.11364},
  urldate = {2025-05-26},
  abstract = {Pre-trained language models derive substantial linguistic and factual knowledge from the massive corpora on which they are trained, and prompt engineering seeks to align these models to specific tasks. Unfortunately, existing prompt engineering methods require significant amounts of labeled data, access to model parameters, or both. We introduce a new method for selecting prompt templates without labeled examples and without direct access to the model. Specifically, over a set of candidate templates, we choose the template that maximizes the mutual information between the input and the corresponding model output. Across 8 datasets representing 7 distinct NLP tasks, we show that when a template has high mutual information, it also has high accuracy on the task. On the largest model, selecting prompts with our method gets 90\% of the way from the average prompt accuracy to the best prompt accuracy and requires no ground truth labels.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/vini84200/Zotero/storage/SLA649CT/Sorensen et al. - 2022 - An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels.pdf}
}

@inproceedings{suarezvargas2021,
  title = {{{sOCRates}} - a Post-{{OCR}} Text Correction Method},
  booktitle = {Anais Do {{XXXVI Simp{\'o}sio Brasileiro}} de {{Banco}} de {{Dados}} ({{SBBD}} 2021)},
  author = {Suarez Vargas, Danny and Lima De Oliveira, Lucas and P. Moreira, Viviane and Torresan Bazzo, Guilherme and Acauan Lorentz, Gustavo},
  year = {2021},
  month = oct,
  pages = {61--72},
  publisher = {Sociedade Brasileira de Computa{\c c}{\~a}o - SBC},
  address = {Brasil},
  doi = {10.5753/sbbd.2021.17866},
  url = {https://sol.sbc.org.br/index.php/sbbd/article/view/17866},
  urldate = {2025-03-17},
  abstract = {A significant portion of the textual information of interest to an organization is stored in PDF files that should be converted into plain text before their contents can be processed by an information retrieval or text mining system. When the PDF documents consist of scanned documents, optical character recognition (OCR) is typically used to extract the textual contents. OCR errors can have a negative impact on the quality of information retrieval systems since the terms in the query will not match incorrectly extracted terms in the documents. This work introduces sOCRates, a post-OCR text correction method that relies on contextual word embeddings and on a classifier that uses format, semantic, and syntactic features. Our experimental evaluation on a test collection in Portuguese showed that sOCRates can accurately correct errors and improve retrieval results.},
  langid = {english},
  keywords = {relevanciaMed},
  file = {/home/vini84200/Zotero/storage/48VYMVQM/Suarez Vargas et al. - 2021 - sOCRates - a post-OCR text correction method.pdf}
}

@misc{tang2024,
  title = {Full-Text {{Error Correction}} for {{Chinese Speech Recognition}} with {{Large Language Model}}},
  author = {Tang, Zhiyuan and Wang, Dong and Huang, Shen and Shang, Shidong},
  year = {2024},
  month = dec,
  number = {arXiv:2409.07790},
  eprint = {2409.07790},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.07790},
  url = {http://arxiv.org/abs/2409.07790},
  urldate = {2025-05-09},
  abstract = {Large Language Models (LLMs) have demonstrated substantial potential for error correction in Automatic Speech Recognition (ASR). However, most research focuses on utterances from short-duration speech recordings, which are the predominant form of speech data for supervised ASR training. This paper investigates the effectiveness of LLMs for error correction in full-text generated by ASR systems from longer speech recordings, such as transcripts from podcasts, news broadcasts, and meetings. First, we develop a Chinese dataset for full-text error correction, named ChFT, utilizing a pipeline that involves text-to-speech synthesis, ASR, and error-correction pair extractor. This dataset enables us to correct errors across contexts, including both full-text and segment, and to address a broader range of error types, such as punctuation restoration and inverse text normalization, thus making the correction process comprehensive. Second, we fine-tune a pre-trained LLM on the constructed dataset using a diverse set of prompts and target formats, and evaluate its performance on full-text error correction. Specifically, we design prompts based on full-text and segment, considering various output formats, such as directly corrected text and JSON-based error-correction pairs. Through various test settings, including homogeneous, up-to-date, and hard test sets, we find that the fine-tuned LLMs perform well in the full-text setting with different prompts, each presenting its own strengths and weaknesses. This establishes a promising baseline for further research. The dataset is available on the website.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computation and Language,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/vini84200/Zotero/storage/333MTTCV/Tang et al. - 2024 - Full-text Error Correction for Chinese Speech Recognition with Large Language Model.pdf;/home/vini84200/Zotero/storage/ZLMWJEC4/2409.html}
}

@inproceedings{thomas2024,
  title = {Leveraging {{LLMs}} for {{Post-OCR Correction}} of {{Historical Newspapers}}},
  booktitle = {Proceedings of the {{Third Workshop}} on {{Language Technologies}} for {{Historical}} and {{Ancient Languages}} ({{LT4HALA}}) @ {{LREC-COLING-2024}}},
  author = {Thomas, Alan and Gaizauskas, Robert and Lu, Haiping},
  editor = {Sprugnoli, Rachele and Passarotti, Marco},
  year = {2024},
  month = may,
  pages = {116--121},
  publisher = {{ELRA and ICCL}},
  address = {Torino, Italia},
  url = {https://aclanthology.org/2024.lt4hala-1.14/},
  urldate = {2025-03-17},
  abstract = {Poor OCR quality continues to be a major obstacle for humanities scholars seeking to make use of digitised primary sources such as historical newspapers. Typical approaches to post-OCR correction employ sequence-to-sequence models for a neural machine translation task, mapping erroneous OCR texts to accurate reference texts. We shift our focus towards the adaptation of generative LLMs for a prompt-based approach. By instruction-tuning Llama 2 and comparing it to a fine-tuned BART on BLN600, a parallel corpus of 19th century British newspaper articles, we demonstrate the potential of a prompt-based approach in detecting and correcting OCR errors, even with limited training data. We achieve a significant enhancement in OCR quality with Llama 2 outperforming BART, achieving a 54.51\% reduction in the character error rate against BART`s 23.30\%. This paves the way for future work leveraging generative LLMs to improve the accessibility and unlock the full potential of historical texts for humanities research.},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/WRZ6YHVR/Thomas et al. - 2024 - Leveraging LLMs for Post-OCR Correction of Historical Newspapers.pdf}
}

@inproceedings{valizadeh2025,
  title = {Comparative {{Analysis}} of {{Large Language Models}} for {{OCR Post-Processing}} in {{Persian}}: {{From ParsBERT}} to {{GPT}}},
  shorttitle = {Comparative {{Analysis}} of {{Large Language Models}} for {{OCR Post-Processing}} in {{Persian}}},
  booktitle = {2025 29th {{International Computer Conference}}, {{Computer Society}} of {{Iran}} ({{CSICC}})},
  author = {Valizadeh, Fatemeh and Ghasemian, Fahimeh and Shabaninia, Elham},
  year = {2025},
  month = feb,
  pages = {1--6},
  doi = {10.1109/CSICC65765.2025.10967472},
  url = {https://ieeexplore.ieee.org/abstract/document/10967472},
  urldate = {2025-05-23},
  abstract = {Optical Character Recognition (OCR) refers to the automatic identification of text in images and its conversion into searchable and editable formats. Due to its extensive applications, OCR is considered a crucial and challenging topic in the field of computer vision. In Persian, the unique characteristics of the script often result in OCR outputs with significant errors, which can compromise readability and comprehension of the content, emphasizing the need for error correction, particularly in terms of spelling. This study investigates the performance of four large language models-ParsBERT, LLaMA, Mistral, and GPT-for enhancing OCR outputs. Additionally, an innovative approach that integrates ParsBERT with other models is introduced. These models were evaluated on three corpora of varying sizes and complexities using diverse evaluation metrics, including precision, accuracy, recall, and others. Our comparative analysis highlights the strengths and weaknesses of each model across different scenarios, providing deeper insights into their performance. Furthermore, the results demonstrate that the proposed hybrid approaches outperform standalone models across all corpora, significantly reducing error rates and improving key metrics such as precision, accuracy, and recall.},
  keywords = {Accuracy,Analytical models,Computational modeling,Error analysis,Error correction,GPT,Large language models,Large Language Models,LLaMA,Measurement,Mistral,Natural language processing,Natural Language Processing (NLP),OCR Post-Processing,Optical character recognition,Optical Character Recognition (OCR),ParsBERT,Pipelines,relevanciaMin,Spell Correction,Transformer},
  file = {/home/vini84200/Zotero/storage/N93ZUCED/Valizadeh et al. - 2025 - Comparative Analysis of Large Language Models for OCR Post-Processing in Persian From ParsBERT to G.pdf;/home/vini84200/Zotero/storage/E3Q85WXC/10967472.html}
}

@misc{vaswani2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = jun,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2025-06-16},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  keywords = {/unread,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/vini84200/Zotero/storage/EURE54CD/Vaswani et al. - 2023 - Attention Is All You Need.pdf;/home/vini84200/Zotero/storage/QIRNVUDC/1706.html}
}

@article{veninga2024,
  title = {{{LLMs}} for {{OCR Post-Correction}}},
  author = {Veninga, M.E.B.},
  year = {2024},
  month = jul,
  url = {http://essay.utwente.nl/102117/},
  abstract = {In this thesis, I examine the use of Large Language Models (LLMs) on the task of Optical Character Recognition (OCR) post-correction. Pretrained LLMs exhibit an understanding of language which can be exploited to correct mistakes in OCR output, but for good performance fine-tuning of the models is needed. I show that fine-tuned versions of the ByT5 LLM are able to correct mistakes in OCR text better than a state-of-the-art method can. Preprocessing techniques are shown to impact the capability of the language models to correct OCR errors. ByT5 models achieve the highest Character Error Rate (CER) reduction rates when using lowercasing as well as removing strange characters. Context length is also shown to have a strong impact on the effectiveness of the models. The best context length was found to be 50 characters, with longer and shorter context lengths having worse CER reduction and worse F1 scores. I also show that few-shot learning is not able to teach a generative LLM to correct OCR text without fine-tuning the model. Future research can investigate the potential increase in effectiveness of fine-tuning larger language models on the post-OCR error correcting task},
  file = {/home/vini84200/Zotero/storage/3TZQFBSL/Veninga - 2024 - LLMs for OCR Post-Correction.pdf;/home/vini84200/Zotero/storage/8IBUVLHM/102117.html}
}

@article{vonahn2008,
  title = {{{reCAPTCHA}}: {{Human-Based Character Recognition}} via {{Web Security Measures}}},
  shorttitle = {{{reCAPTCHA}}},
  author = {Von Ahn, Luis and Maurer, Benjamin and McMillen, Colin and Abraham, David and Blum, Manuel},
  year = {2008},
  month = sep,
  journal = {Science},
  volume = {321},
  number = {5895},
  pages = {1465--1468},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1160379},
  url = {https://www.science.org/doi/10.1126/science.1160379},
  urldate = {2025-05-26},
  abstract = {CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) are widespread security measures on the World Wide Web that prevent automated programs from abusing online services. They do so by asking humans to perform a task that computers cannot yet perform, such as deciphering distorted characters. Our research explored whether such human effort can be channeled into a useful purpose: helping to digitize old printed material by asking users to decipher scanned words from books that computerized optical character recognition failed to recognize. We showed that this method can transcribe text with a word accuracy exceeding 99\%, matching the guarantee of professional human transcribers. Our apparatus is deployed in more than 40,000 Web sites and has transcribed over 440 million words.},
  langid = {english},
  keywords = {/unread},
  file = {/home/vini84200/Zotero/storage/WNTXR2TU/Von Ahn et al. - 2008 - reCAPTCHA Human-Based Character Recognition via Web Security Measures.pdf}
}

@inproceedings{xu2017,
  title = {Retrieving and {{Combining Repeated Passages}} to {{Improve OCR}}},
  booktitle = {2017 {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}} ({{JCDL}})},
  author = {Xu, Shaobin and Smith, David},
  year = {2017},
  month = jun,
  pages = {1--4},
  doi = {10.1109/JCDL.2017.7991587},
  url = {https://ieeexplore.ieee.org/abstract/document/7991587},
  urldate = {2025-05-31},
  abstract = {We present a novel approach to improve the output of optical character recognition (OCR) systems by first detecting duplicate passages in their output and then performing consensus decoding combined with a language model. This approach is orthogonal to, and may be combined with, previously proposed methods for combining the output of different OCR systems on the same image or the output of the same OCR system on differently processed images of the same text. It may also be combined with methods to estimate the parameters of a noisy channel model of OCR errors. Additionally, the current method generalizes previous proposals for a simple majority- vote combination of known duplicated texts. On a corpus of historical newspapers, an annotated set of clusters has a baseline word error rate (WER) of 33\%. A majority vote procedure reaches 23\% on passages where one or more duplicates were found, and consensus decoding combined with a language model achieves 18\% WER. In a separate experiment, newspapers were aligned to very widely reprinted texts such as State of the Union speeches, producing clusters with up to 58 witnesses. Beyond 20 witnesses, majority vote outperforms language model rescoring, though the gap between them is much less in this experiment.},
  keywords = {/unread,Clustering algorithms,Decoding,Engines,Error analysis,Lattices,Noise measurement,Optical character recognition software,relevanciaMin},
  file = {/home/vini84200/Zotero/storage/96RTXWQV/Xu e Smith - 2017 - Retrieving and Combining Repeated Passages to Improve OCR.pdf}
}
